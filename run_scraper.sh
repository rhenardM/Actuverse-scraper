#!/bin/bash

# =============================================================================
# ActuVerse - Script d'automatisation du scraping
# =============================================================================
# Ce script lance automatiquement le scraping des articles et peut Ãªtre 
# configurÃ© dans un cron job pour une exÃ©cution pÃ©riodique
# =============================================================================

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
VENV_PATH="$SCRIPT_DIR/.venv"
PYTHON_SCRIPT="$SCRIPT_DIR/main.py"
LOG_DIR="$SCRIPT_DIR/logs"
LOCK_FILE="/tmp/actuverse_scraper.lock"

# Fonction de logging
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_DIR/automation.log"
}

# Fonction de nettoyage
cleanup() {
    rm -f "$LOCK_FILE"
    log "ğŸ§¹ Nettoyage terminÃ©"
}

# PiÃ¨ge pour nettoyer en cas d'interruption
trap cleanup EXIT INT TERM

# =============================================================================
# VÃ‰RIFICATIONS PRÃ‰LIMINAIRES
# =============================================================================

# VÃ©rifier si un autre processus est en cours
if [ -f "$LOCK_FILE" ]; then
    log "âš ï¸ Un autre processus de scraping est dÃ©jÃ  en cours (lock file existe)"
    exit 1
fi

# CrÃ©er le lock file
echo $$ > "$LOCK_FILE"

# CrÃ©er le dossier de logs s'il n'existe pas
mkdir -p "$LOG_DIR"

log "ğŸš€ DÃ©marrage du scraping automatique ActuVerse"

# VÃ©rifier que l'environnement virtuel existe
if [ ! -d "$VENV_PATH" ]; then
    log "âŒ Environnement virtuel non trouvÃ©: $VENV_PATH"
    exit 1
fi

# VÃ©rifier que le script Python existe
if [ ! -f "$PYTHON_SCRIPT" ]; then
    log "âŒ Script Python non trouvÃ©: $PYTHON_SCRIPT"
    exit 1
fi

# =============================================================================
# CONFIGURATION DES PARAMÃˆTRES
# =============================================================================

# ParamÃ¨tres par dÃ©faut
SITES="sur7cd bbc france24 mediacongo"
HOURS_FILTER=2  # Ne rÃ©cupÃ©rer que les articles des 2 derniÃ¨res heures
CHECK_DUPLICATES=true

# Permettre la personnalisation via variables d'environnement
SITES="${ACTUVERSE_SITES:-$SITES}"
HOURS_FILTER="${ACTUVERSE_HOURS_FILTER:-$HOURS_FILTER}"

log "ğŸ“‹ Configuration:"
log "   Sites: $SITES"
log "   Filtre horaire: ${HOURS_FILTER}h"
log "   VÃ©rification doublons: $CHECK_DUPLICATES"

# =============================================================================
# EXÃ‰CUTION DU SCRAPING
# =============================================================================

# Activer l'environnement virtuel et lancer le scraping
cd "$SCRIPT_DIR"
source "$VENV_PATH/bin/activate"

log "ğŸ” Lancement du scraping..."

# Construire la commande Python
PYTHON_CMD="python $PYTHON_SCRIPT --sites $SITES --hours $HOURS_FILTER"

if [ "$CHECK_DUPLICATES" = "false" ]; then
    PYTHON_CMD="$PYTHON_CMD --no-check"
fi

# ExÃ©cuter le scraping avec gestion des erreurs
if $PYTHON_CMD 2>&1 | tee -a "$LOG_DIR/scraping_$(date +%Y%m%d).log"; then
    log "âœ… Scraping terminÃ© avec succÃ¨s"
    exit_code=0
else
    exit_code=$?
    log "âŒ Erreur lors du scraping (code: $exit_code)"
fi

# =============================================================================
# NETTOYAGE ET MAINTENANCE
# =============================================================================

# Nettoyer les anciens logs (garder seulement les 7 derniers jours)
log "ğŸ§¹ Nettoyage des anciens logs..."
find "$LOG_DIR" -name "*.log" -type f -mtime +7 -delete 2>/dev/null || true

# Statistiques rapides
log "ğŸ“Š Statistiques des logs rÃ©cents:"
recent_logs=$(find "$LOG_DIR" -name "scraper_*.log" -type f -mtime -1 | wc -l)
log "   Logs des derniÃ¨res 24h: $recent_logs"

total_log_size=$(du -sh "$LOG_DIR" 2>/dev/null | cut -f1)
log "   Taille totale des logs: $total_log_size"

log "ğŸ Script d'automatisation terminÃ© (code: $exit_code)"
exit $exit_code
