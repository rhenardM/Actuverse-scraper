# ğŸ¤– Guide d'Automatisation ActuVerse

Ce guide explique comment configurer l'automatisation complÃ¨te du scraping pour rÃ©cupÃ©rer automatiquement les nouveaux articles.

## ğŸ¯ FonctionnalitÃ©s automatiques

âœ… **DÃ©tection des nouveaux articles** : Seuls les articles non prÃ©sents en base sont rÃ©cupÃ©rÃ©s  
âœ… **Filtrage temporel** : RÃ©cupÃ©ration des articles rÃ©cents uniquement (configurable)  
âœ… **CatÃ©gorisation automatique** : Chaque article est catÃ©gorisÃ© avant envoi  
âœ… **Logging complet** : TraÃ§age de toutes les opÃ©rations  
âœ… **Protection contre les doublons** : VÃ©rification en base avant insertion  

## ğŸš€ Utilisation

### Mode manuel avec nouvelles fonctionnalitÃ©s

```bash
# RÃ©cupÃ©rer seulement les nouveaux articles des derniÃ¨res 24h
python main.py --sites france24 sur7cd

# RÃ©cupÃ©rer les articles des 2 derniÃ¨res heures seulement
python main.py --sites bbc --hours 2

# Mode test avec affichage des nouveaux articles dÃ©tectÃ©s
python main.py --sites mediacongo --dry-run

# DÃ©sactiver la vÃ©rification des doublons (rÃ©cupÃ©rer tous les articles)
python main.py --sites sur7cd --no-check

# RÃ©cupÃ©rer les articles de la derniÃ¨re semaine
python main.py --sites france24 --hours 168
```

### Script d'automatisation

```bash
# Lancer le script d'automatisation (mode production)
./run_scraper.sh

# Le script utilise automatiquement :
# - Filtre 2 heures par dÃ©faut
# - VÃ©rification des doublons activÃ©e
# - Tous les sites configurÃ©s
# - Logging complet
```

## âš™ï¸ Configuration du Cron Job

### 1. Ã‰diter la crontab
```bash
crontab -e
```

### 2. Exemples de configuration

```bash
# Toutes les heures
0 * * * * /Users/user/Documents/Workspace/ActuVerse/Scraper/Test/actuverse_scraper/run_scraper.sh

# Toutes les 30 minutes
*/30 * * * * /Users/user/Documents/Workspace/ActuVerse/Scraper/Test/actuverse_scraper/run_scraper.sh

# Toutes les 15 minutes (haute frÃ©quence)
*/15 * * * * /Users/user/Documents/Workspace/ActuVerse/Scraper/Test/actuverse_scraper/run_scraper.sh

# Tous les jours Ã  8h et 20h
0 8,20 * * * /Users/user/Documents/Workspace/ActuVerse/Scraper/Test/actuverse_scraper/run_scraper.sh

# Du lundi au vendredi Ã  9h, 12h, 15h, 18h
0 9,12,15,18 * * 1-5 /Users/user/Documents/Workspace/ActuVerse/Scraper/Test/actuverse_scraper/run_scraper.sh
```

### 3. Configuration recommandÃ©e pour ActuVerse
```bash
# Scraping toutes les heures pendant les heures de bureau
0 8-22 * * * /path/to/actuverse_scraper/run_scraper.sh

# Scraping rÃ©duit la nuit et le weekend
0 0,6,12,18 * * 0,6 /path/to/actuverse_scraper/run_scraper.sh
```

## ğŸ› ï¸ Personnalisation

### Variables d'environnement pour run_scraper.sh

```bash
# Modifier les sites Ã  scraper
export ACTUVERSE_SITES="france24 bbc"

# Modifier le filtre horaire (en heures)
export ACTUVERSE_HOURS_FILTER=1

# Puis lancer
./run_scraper.sh
```

### ParamÃ¨tres avancÃ©s

```bash
# Scraping avec paramÃ¨tres personnalisÃ©s
python main.py \
  --sites france24 sur7cd \
  --hours 6 \
  --no-check

# Affichage complet en mode test
python main.py \
  --sites bbc \
  --dry-run \
  --full-content \
  --hours 12
```

## ğŸ“Š Monitoring et Logs

### Localisation des logs
```
logs/
â”œâ”€â”€ automation.log          # Logs du script d'automatisation
â”œâ”€â”€ scraper_YYYYMMDD.log   # Logs dÃ©taillÃ©s par jour
â””â”€â”€ scraping_YYYYMMDD.log  # Sortie complÃ¨te du scraping
```

### Commandes de monitoring
```bash
# Voir les derniers logs en temps rÃ©el
tail -f logs/automation.log

# Statistiques du jour
grep "STATISTIQUES GLOBALES" logs/scraper_$(date +%Y%m%d).log

# Compter les nouveaux articles du jour
grep "nouveaux articles" logs/scraper_$(date +%Y%m%d).log | wc -l

# Voir les erreurs rÃ©centes
grep "ERROR\|âŒ" logs/scraper_$(date +%Y%m%d).log
```

## ğŸ”§ DÃ©pannage

### ProblÃ¨mes courants

1. **Aucun nouvel article rÃ©cupÃ©rÃ©**
   ```bash
   # VÃ©rifier avec un filtre plus large
   python main.py --sites france24 --hours 48 --dry-run
   ```

2. **Erreur de connexion API**
   ```bash
   # Tester la connexion Ã  l'API
   curl -X POST "http://127.0.0.1:8000/api/articles/check" \
     -H "Content-Type: application/json" \
     -d '{"urls":["test"]}'
   ```

3. **Script d'automatisation bloquÃ©**
   ```bash
   # Supprimer le lock file
   rm -f /tmp/actuverse_scraper.lock
   ```

### DÃ©sactiver temporairement l'automatisation
```bash
# Commenter la ligne dans crontab
crontab -e
# Ajouter # devant la ligne de scraping

# Ou dÃ©sactiver complÃ¨tement
crontab -r
```

## ğŸ“ˆ Optimisation des performances

### RÃ©glages recommandÃ©s par contexte

**ActualitÃ©s en temps rÃ©el** (15-30 min)
```bash
*/15 * * * * /path/to/run_scraper.sh
export ACTUVERSE_HOURS_FILTER=1
```

**ActualitÃ©s quotidiennes** (2-6 heures)
```bash
0 */4 * * * /path/to/run_scraper.sh
export ACTUVERSE_HOURS_FILTER=8
```

**Archivage hebdomadaire** (1-7 jours)
```bash
0 0 * * 0 /path/to/run_scraper.sh
export ACTUVERSE_HOURS_FILTER=168
```

## ğŸ›¡ï¸ SÃ©curitÃ© et maintenance

### Rotation des logs
```bash
# Nettoyage automatique (dans run_scraper.sh)
find logs/ -name "*.log" -type f -mtime +7 -delete
```

### Sauvegarde des configurations
```bash
# Sauvegarder la crontab actuelle
crontab -l > backup_crontab.txt

# Sauvegarder les logs importants
cp logs/automation.log backup/automation_$(date +%Y%m%d).log
```

### Surveillance de l'espace disque
```bash
# VÃ©rifier l'espace utilisÃ© par les logs
du -sh logs/

# Nettoyer manuellement si nÃ©cessaire
find logs/ -name "*.log" -type f -mtime +3 -delete
```

## ğŸ¯ RÃ©sumÃ©

Une fois configurÃ©, le systÃ¨me automatique :

1. âœ… **DÃ©tecte automatiquement** les nouveaux articles sur vos sites ciblÃ©s
2. âœ… **Ã‰vite les doublons** en vÃ©rifiant l'existence en base
3. âœ… **Filtre par date** pour ne rÃ©cupÃ©rer que les articles rÃ©cents
4. âœ… **CatÃ©gorise automatiquement** chaque article
5. âœ… **Envoie vers votre API** Symfony en temps rÃ©el
6. âœ… **Log toutes les opÃ©rations** pour monitoring et debugging

**ğŸ‰ Votre plateforme ActuVerse sera alimentÃ©e automatiquement en contenu frais !**
